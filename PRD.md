# Product Requirements Document (PRD)
## AI-Powered Chrome Extension - Local-First AI Assistant

**Version:** 1.0  
**Date:** October 15, 2025  
**Status:** Draft  
**Author:** Product Manager

---

## 1. Executive Summary

### 1.1 Product Vision
Build a privacy-first, local AI assistant as a Chrome extension that runs powerful AI models directly in the browser without requiring external API calls or cloud services. Users can interact with multiple AI capabilities (text generation, image creation, speech recognition, and speech synthesis) seamlessly within their browser.

### 1.2 Problem Statement
- **Privacy Concerns**: Users are hesitant to share sensitive data with cloud-based AI services
- **Connectivity Dependence**: Traditional AI assistants require constant internet connectivity
- **Cost Barriers**: API-based AI services have usage costs that limit accessibility
- **Latency Issues**: Round-trip API calls introduce delays in user experience

### 1.3 Solution Overview
A Chrome extension that leverages WebGPU and WebAssembly to run optimized AI models locally in the browser, providing:
- Zero-cost AI interactions after initial model download
- Complete data privacy (no data leaves the device)
- Offline functionality after model caching
- Low-latency responses
- Multi-modal AI capabilities (text, image, speech)

---

## 2. Product Goals & Success Metrics

### 2.1 Goals
1. **Privacy**: 100% local processing, zero data transmission to external servers
2. **Accessibility**: Free to use after initial model download
3. **Performance**: Response latency <2s for text generation (after model load)
4. **Usability**: Intuitive chat interface comparable to ChatGPT
5. **Flexibility**: Support multiple AI tasks and customizable models

### 2.2 Key Performance Indicators (KPIs)
- **Adoption**: 10,000+ active users in first 3 months
- **Engagement**: Average 5+ interactions per user per day
- **Retention**: 60% 30-day retention rate
- **Performance**: 90% of users report satisfactory response speed
- **NPS**: Net Promoter Score >40

### 2.3 Success Criteria
- Successfully run AI models on devices with 8GB+ RAM
- Support Chrome 90+ with WebGPU enabled
- Model loading time <60 seconds for small models
- Average response generation time <3 seconds

---

## 4. Functional Requirements

### 4.1 Core Features

#### 4.1.1 Chat Interface
**Priority**: P0 (Must Have)

**Description**: Primary interaction interface for users to communicate with AI models

**Requirements**:
- Clean, modern chat UI similar to ChatGPT/Claude
- Support for message history within session
- Markdown rendering with code syntax highlighting
- LaTeX/Math equation rendering (MathJax)
- Copy message to clipboard functionality
- Clear chat history option
- Message streaming (token-by-token display)
- User and assistant message differentiation

**User Stories**:
- As a user, I want to type messages and receive AI responses in a conversational format
- As a user, I want to see my message history to maintain context
- As a developer, I want to copy code snippets easily from responses

#### 4.1.2 Text Generation (LLM)
**Priority**: P0 (Must Have)

**Description**: Generate human-like text responses using large language models

**Requirements**:
- Support multiple LLM models:
  - SmolLM-135M-Instruct (lightweight)
  - Phi-3.5-mini-instruct (medium)
  - Qwen2.5-0.5B-Instruct
  - Llama-3.2-1B-Instruct
  - Custom user-added models
- Configurable generation parameters:
  - Temperature (0.0-2.0)
  - Top-p (nucleus sampling)
  - Top-k sampling
  - Max tokens
  - Repetition penalty
- Streaming text generation
- Stop generation capability
- Session-based context retention

**User Stories**:
- As a user, I want to ask questions and get intelligent responses
- As a user, I want to choose different models based on my needs
- As a user, I want to adjust creativity/randomness of responses

#### 4.1.3 Image Generation
**Priority**: P1 (Should Have)

**Description**: Generate images from text descriptions using multimodal models

**Requirements**:
- Command-based activation (e.g., `/image [prompt]`)
- Support multimodal LLM models for image generation
- Display generated images inline in chat
- Download generated images functionality
- Progress indicator during generation
- Support custom image generation models

**User Stories**:
- As a user, I want to create images by describing them in text
- As a user, I want to download generated images to my device
- As a creative professional, I want quick visual prototypes without external tools

#### 4.1.4 Speech-to-Text (STT)
**Priority**: P1 (Should Have)

**Description**: Transcribe audio recordings to text using Whisper models

**Requirements**:
- In-browser audio recording capability
- Support multiple Whisper model variants:
  - Whisper-tiny
  - Whisper-base
  - Whisper-small (if memory allows)
- Real-time transcription display
- Support multiple languages
- Audio waveform visualization
- Recording timer
- File upload for transcription (audio files)

**User Stories**:
- As a user, I want to speak my messages instead of typing
- As a researcher, I want to transcribe interviews quickly
- As a student, I want to transcribe lecture recordings

#### 4.1.5 Text-to-Speech (TTS)
**Priority**: P2 (Nice to Have)

**Description**: Convert text responses to natural speech audio

**Requirements**:
- Play button on AI responses to hear audio
- Configurable voice characteristics
- Speaker selection
- Pause/resume audio playback
- WebGPU-accelerated inference

**User Stories**:
- As a visually impaired user, I want to hear responses
- As a multitasking user, I want to listen while doing other tasks
- As a language learner, I want to hear correct pronunciation

#### 4.1.6 Reasoning Models
**Priority**: P2 (Nice to Have)

**Description**: Support specialized reasoning models for complex problem-solving

**Requirements**:
- Support reasoning-specific models (e.g., DeepSeek-R1)
- Chain-of-thought display
- Step-by-step reasoning breakdown
- Longer context windows for complex problems

**User Stories**:
- As a student, I want step-by-step solutions to math problems
- As an analyst, I want to see the AI's reasoning process

### 4.2 Model Management

#### 4.2.1 Model Selection
**Priority**: P0 (Must Have)

**Description**: Allow users to switch between different AI models

**Requirements**:
- Modal/dialog for model selection
- Group models by task type:
  - Text Generation
  - Image Generation
  - Speech-to-Text
  - Text-to-Speech
  - Reasoning
- Display model metadata:
  - Model name
  - Size
  - Description
  - Recommended hardware
- Visual indicators for currently selected model
- Task-specific icons (brain, image, audio, text icons)

**User Stories**:
- As a user, I want to easily switch between models based on my task
- As a user, I want to know model sizes before downloading

#### 4.2.2 Model Registry & Cache Management
**Priority**: P0 (Must Have)

**Description**: Manage downloaded models and browser cache

**Requirements**:
- List all cached models with metadata:
  - Model name
  - File size
  - Last used date
  - Cache status
- Delete individual models from cache
- Clear all models option
- Total cache size display
- Storage usage warnings
- Model download progress tracking

**User Stories**:
- As a user with limited storage, I want to see and manage cached models
- As a user, I want to clear space by removing unused models
- As a user, I want to know how much storage models consume

#### 4.2.3 Custom Model Addition
**Priority**: P2 (Nice to Have)

**Description**: Allow users to add custom models from Hugging Face

**Requirements**:
- Form to input:
  - Model ID (Hugging Face path)
  - Task type
  - Model name/description
- Validation of model compatibility
- Support for quantized models (ONNX format)
- Test model before saving
- Save custom model configurations

**User Stories**:
- As an advanced user, I want to use specific models not in the default list
- As a researcher, I want to test my own fine-tuned models

### 4.3 Configuration & Settings

#### 4.3.1 Generation Configuration
**Priority**: P1 (Should Have)

**Description**: Fine-tune AI generation parameters

**Requirements**:
- Adjustable parameters:
  - Temperature (creativity)
  - Top-p (diversity)
  - Top-k (vocabulary restriction)
  - Max new tokens (response length)
  - Repetition penalty
  - Do sample (enable sampling)
- Presets for common use cases:
  - Creative writing (high temp)
  - Factual responses (low temp)
  - Balanced (medium)
- Save/load configurations
- Reset to defaults
- Real-time parameter explanations

**User Stories**:
- As a writer, I want more creative responses
- As a researcher, I want more factual, deterministic outputs
- As a user, I want to understand what each parameter does

#### 4.3.2 Hardware Preferences
**Priority**: P1 (Should Have)

**Description**: Configure hardware utilization

**Requirements**:
- WebGPU vs WebAssembly selection
- Thread count configuration (for WASM)
- Memory limit settings
- Device capability detection
- Performance warnings for low-end devices
- FP16 support toggle (if available)

**User Stories**:
- As a user with a powerful GPU, I want to use WebGPU for speed
- As a user with limited resources, I want to optimize for memory

### 4.4 User Experience Features

#### 4.4.1 Example Prompts
**Priority**: P1 (Should Have)

**Description**: Provide suggested prompts for new users

**Requirements**:
- Task-specific examples:
  - Text generation examples
  - Image generation examples
  - Transcription examples
- One-click example usage
- Context-aware examples (based on selected model)
- Dismissible examples section

**User Stories**:
- As a new user, I want to see what I can do with this extension
- As a user, I want quick access to common tasks

#### 4.4.2 Progress Indicators
**Priority**: P0 (Must Have)

**Description**: Show model loading and generation progress

**Requirements**:
- Model download progress:
  - File name
  - Downloaded size / total size
  - Progress percentage
  - Download speed
- Generation progress:
  - "Thinking" animation
  - Token generation speed
- Cancellable operations

**User Stories**:
- As a user, I want to know how long model loading will take
- As a user, I want to cancel long-running operations

#### 4.4.3 Error Handling & Recovery
**Priority**: P0 (Must Have)

**Description**: Graceful error handling with user-friendly messages

**Requirements**:
- Error categories:
  - Out of memory
  - Model not found
  - WebGPU not supported
  - Network errors (during download)
  - Generation errors
- Actionable error messages
- Automatic fallback to WASM if WebGPU fails
- Retry mechanisms
- Error logging (locally)

**User Stories**:
- As a user, I want clear explanations when something goes wrong
- As a user, I want suggestions on how to fix errors

---

## 5. Non-Functional Requirements

### 5.1 Performance
- **Model Loading**: <60s for models <500MB
- **First Token Latency**: <2s after model is loaded
- **Token Generation Speed**: >5 tokens/second on average hardware
- **Memory Footprint**: <2GB RAM usage for small models
- **UI Responsiveness**: All UI interactions <100ms

### 5.2 Compatibility
- **Browser**: Chrome 90+ (WebGPU requires Chrome 113+)
- **Operating Systems**: Windows 10+, macOS 11+, Linux
- **Hardware**: 
  - Minimum: 8GB RAM, modern CPU
  - Recommended: 16GB RAM, discrete GPU
- **Storage**: 2-10GB available space (depends on models)

### 5.3 Security & Privacy
- **Zero Data Transmission**: No external API calls for AI inference
- **Local Storage Only**: All data stored in browser cache
- **Content Security Policy**: Strict CSP implementation
- **No Telemetry**: Optional anonymous usage statistics only
- **Model Integrity**: Verify model checksums from Hugging Face

### 5.4 Accessibility
- **WCAG 2.1 Level AA Compliance**
- **Keyboard Navigation**: Full functionality via keyboard
- **Screen Reader Support**: ARIA labels and semantic HTML
- **High Contrast Mode**: Support for OS-level contrast settings
- **Font Scaling**: Responsive to browser zoom levels

### 5.5 Scalability
- **Model Support**: Architecture supports adding new models without code changes
- **Task Extensibility**: Plugin-like architecture for new AI tasks
- **Storage Management**: Automatic cache cleanup when storage is low

### 5.6 Reliability
- **Uptime**: Extension should not crash or hang
- **State Persistence**: Chat history saved between sessions
- **Graceful Degradation**: Fallback to simpler models if resources are limited
- **Error Recovery**: Automatic retry for transient failures

---

## 6. Technical Architecture

### 6.1 Technology Stack
- **Frontend Framework**: React 19 (functional components with hooks)
- **Build Tool**: Vite 7.x
- **AI Runtime**: Hugging Face Transformers.js
- **Acceleration**: WebGPU
- **Styling**: Tailwind CSS + shadcn/ui components
- **State Management**: React hooks
- **Type Safety**: TypeScript
- **Markdown Parsing**: marked + DOMPurify

### 6.2 Architecture Patterns
- **Component-Based Architecture**: Reusable UI components
- **Pipeline Pattern**: Separate pipelines for each AI task
- **Storage Layer**: Abstraction over Chrome storage APIs
- **Worker-Based Inference**: Offload heavy computation to Web Workers
- **Lazy Loading**: Models loaded on-demand

### 6.3 Key Components

#### Frontend Layer
- `Chat.tsx`: Main chat interface
- `ChatMessages.tsx`: Message rendering with markdown/LaTeX
- `ChatHeader.tsx`: Top navigation and settings
- `ChatExamples.tsx`: Example prompt suggestions
- `ChatProgress.tsx`: Loading and progress indicators
- `ChangeModelForm.tsx`: Model selection UI
- `ModelRegistryForm.tsx`: Cache management UI
- `GenerationConfigForm.tsx`: Parameter configuration UI
- `AudioRecorder.tsx`: Audio recording component

#### AI Pipeline Layer
- `text-generation.ts`: LLM inference pipeline
- `multimodal-llm.ts`: Image generation pipeline
- `speech-to-text.ts`: Whisper transcription pipeline
- `text-to-speech.ts`: TTS synthesis pipeline

#### Utility Layer
- `model-registry.ts`: Model caching and retrieval
- `model-list.ts`: Available models configuration
- `stopping-criteria.ts`: Generation control
- `whisper-text-streamer.ts`: STT streaming

### 6.4 Data Flow
1. User enters prompt in Chat component
2. Chat component determines task type (text/image/audio)
3. Appropriate pipeline is initialized (lazy load if needed)
4. Model loaded from cache or downloaded (with progress)
5. Inference runs in Web Worker (non-blocking)
6. Results streamed back to UI
7. Messages rendered with appropriate formatting
8. State persisted to Chrome storage

### 6.5 Storage Strategy
- **Chrome Local Storage**: Chat history, preferences, model configs
- **Cache API**: Downloaded model files (ONNX weights)
- **IndexedDB**: Large binary data if needed

---

## 7. User Interface Design

### 7.1 Design Principles
- **Minimalist**: Clean, distraction-free interface with maximum focus on conversation
- **Familiar**: Similar to modern AI chat interfaces (ChatGPT/Claude) for zero learning curve
- **Spacious**: Generous whitespace and breathing room for better readability
- **Contextual**: Show relevant features only when needed (sources, attachments)
- **Consistent**: Use shadcn/ui design system throughout with subtle branding

### 7.2 Key Screens

#### 7.2.1 Main Chat Screen (Active State)
**Layout**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚óè AI Assistant    GPT-4o                 Reset            ‚îÇ ‚Üê Header Bar
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  ‚ñ≤  Hello! I'm your AI assistant. I can help you  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     with coding questions, explain concepts, and   ‚îÇ    ‚îÇ ‚Üê AI Message
‚îÇ  ‚îÇ     provide guidance on web development topics.    ‚îÇ    ‚îÇ   (with avatar)
‚îÇ  ‚îÇ     What would you like to know?                   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     Used 2 sources  ÀÖ                              ‚îÇ    ‚îÇ ‚Üê Sources Indicator
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ÔøΩ  üé§  Ask me anything about development, coding, or  [‚Üí] ‚îÇ ‚Üê Input Bar
‚îÇ        technology...                      GPT-4o  ÀÖ         ‚îÇ   with tools
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Visual Elements**:
- **Status Indicator**: Green dot (‚óè) showing AI is active/ready
- **Model Badge**: Current model name displayed prominently in header
- **Reset Button**: Top-right corner for clearing conversation
- **Avatar Icons**: Triangular icon (‚ñ≤) for AI assistant in message bubbles
- **Message Bubbles**: Subtle background with rounded corners
- **Source Attribution**: Collapsible "Used X sources" with dropdown
- **Tool Icons**: Attachment (üìé) and Voice (üé§) input options
- **Model Selector**: Dropdown in input area to switch models quickly
- **Send Button**: Arrow (‚Üí) button to submit message

#### 7.2.2 Chat Screen with Conversation
**Layout**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚óè AI Assistant    GPT-4o                 Reset            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  ‚ñ≤  Hello! I'm your AI assistant...                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     Used 2 sources  ÀÖ                              ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  What is quantum computing?                   üë§    ‚îÇ    ‚îÇ ‚Üê User Message
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÄ‚îÄ‚îò    ‚îÇ   (right aligned)
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  ‚ñ≤  Quantum computing is a revolutionary type of    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     computation that leverages quantum mechanics    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     principles...                                   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     [Copy]  [Regenerate]  [Read Aloud]              ‚îÇ    ‚îÇ ‚Üê Message Actions
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ÔøΩ  üé§  Ask me anything about development, coding, or  [‚Üí] ‚îÇ
‚îÇ        technology...                      GPT-4o  ÀÖ         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 7.2.3 Empty State (First Launch)
**Layout**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚óè AI Assistant    GPT-4o                 Reset            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ                  ‚îÇ      ‚ñ≤       ‚îÇ                          ‚îÇ
‚îÇ                  ‚îÇ  AI  Icon    ‚îÇ                          ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ         Welcome to Your Local AI Assistant                 ‚îÇ
‚îÇ              Privacy-First ‚Ä¢ Offline-Ready                  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  üìù Help me write a function to sort an array   ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  üñºÔ∏è /image Create a futuristic city skyline      ‚îÇ      ‚îÇ ‚Üê Example Prompts
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ   (clickable)
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  üí° Explain machine learning in simple terms     ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üìé  üé§  Ask me anything about development, coding, or  [‚Üí] ‚îÇ
‚îÇ        technology...                      GPT-4o  ÀÖ         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
#### 7.2.4 Model Selection Dropdown
**Layout**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üìé  üé§  Ask me anything...                             [‚Üí] ‚îÇ
‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ                          ‚îÇ GPT-4o            ‚úì      ‚îÇ       ‚îÇ
‚îÇ                          ‚îÇ GPT-4o-mini              ‚îÇ       ‚îÇ
‚îÇ                          ‚îÇ Claude-3.5               ‚îÇ       ‚îÇ
‚îÇ                          ‚îÇ SmolLM-135M              ‚îÇ       ‚îÇ
‚îÇ                          ‚îÇ Phi-3.5-mini             ‚îÇ       ‚îÇ
‚îÇ                          ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ      ‚îÇ       ‚îÇ
‚îÇ                          ‚îÇ ‚öôÔ∏è  Manage Models        ‚îÇ       ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 7.2.5 Settings/Configuration Modal
**Layout**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Settings                                           [‚úï]     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  Model Configuration                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Current Model: GPT-4o                             ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Status: ‚óè Active                                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  [Change Model]                                    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Generation Settings                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Temperature:        [‚îÅ‚îÅ‚óè‚îÅ‚îÅ‚îÅ] 0.7                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Max Tokens:         [‚îÅ‚îÅ‚îÅ‚óè‚îÅ‚îÅ] 500                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Top-p:              [‚îÅ‚îÅ‚îÅ‚óè‚îÅ‚îÅ] 0.9                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Repetition Penalty: [‚îÅ‚îÅ‚óè‚îÅ‚îÅ‚îÅ] 1.0                  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Storage & Cache                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Cached Models: 3 (2.5 GB / 10 GB)                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  [Manage Storage]                                  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                      [Cancel]  [Save Changes]               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 7.2.6 Source Attribution Panel (Expanded)
**Layout**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚ñ≤  Quantum computing is a revolutionary type...   ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ     Used 2 sources  ÀÖ                              ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ     ‚îÇ  üìÑ Wikipedia: Quantum Computing        ‚îÇ    ‚îÇ
‚îÇ     ‚îÇ  üîó https://en.wikipedia.org/wiki/...   ‚îÇ    ‚îÇ
‚îÇ     ‚îÇ                                          ‚îÇ    ‚îÇ
‚îÇ     ‚îÇ  üìÑ MIT Technology Review               ‚îÇ    ‚îÇ
‚îÇ     ‚îÇ  üîó https://www.technologyreview.com... ‚îÇ    ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 7.3 Interaction Patterns
- **Message Sending**: 
  - Enter to send message
  - Shift+Enter for new line within message
  - Click arrow button (‚Üí) to send
- **Model Switching**: 
  - Click model name dropdown in input bar
  - Select from list of available models
  - Models with ‚úì indicate currently active
- **Settings Access**: 
  - Three-dot menu in header (future)
  - Or through model dropdown ‚Üí "Manage Models"
- **Reset/Clear Chat**: 
  - "Reset" button in top-right header
  - Confirmation dialog before clearing
- **Voice Input**:
  - Click microphone icon (üé§)
  - Speak message
  - Auto-transcription appears in input
  - Edit if needed, then send
- **File Attachment**:
  - Click attachment icon (üìé)
  - Upload images, documents, or audio files
  - Preview shown before sending
- **Source Expansion**:
  - Click "Used X sources ÀÖ" to expand
  - See list of referenced sources
  - Click source links to visit original
- **Message Actions**:
  - **Copy**: Copy AI response to clipboard
  - **Regenerate**: Re-generate response with same prompt
  - **Read Aloud**: Text-to-speech playback of response
- **Keyboard Shortcuts**:
  - `Cmd/Ctrl + K`: Focus input field
  - `Cmd/Ctrl + L`: Clear chat (with confirmation)
  - `Cmd/Ctrl + M`: Toggle model selector
  - `Cmd/Ctrl + ,`: Open settings
  - `Esc`: Close modals/dropdowns

### 7.4 Visual Design Specifications

#### Color Palette
- **Primary**: Brand green for status indicator (‚óè)
- **Background**: Clean white/light gray (#FAFAFA)
- **Message Bubbles**: Subtle gray background (#F5F5F5)
- **Text**: Dark gray (#1F1F1F) for readability
- **Accents**: Blue for links, green for active states
- **Borders**: Light gray (#E5E5E5) for subtle separation

#### Typography
- **Header**: Sans-serif, 14-16px, medium weight
- **Body Text**: Sans-serif, 14px, regular weight
- **Code**: Monospace font for code blocks
- **Placeholder**: Lighter gray, italic for input hints

#### Spacing
- **Message Padding**: 16px internal padding
- **Message Margin**: 12px between messages
- **Screen Padding**: 16-24px from edges
- **Input Height**: 48-56px minimum for accessibility

#### Animation
- **Message Appearance**: Subtle fade-in + slide-up (200ms)
- **Streaming Text**: Cursor blink during generation
- **Button Hover**: Gentle background color transition (150ms)
- **Modal Entry**: Fade + scale animation (250ms)

### 7.5 Responsive Behavior
- **Desktop (>1024px)**: Full width with max-width constraint for readability
- **Tablet (768-1024px)**: Compact padding, full feature set
- **Mobile/Narrow (<768px)**: 
  - Stacked layout
  - Simplified header (icons only)
  - Bottom sheet for settings
  - Full-width messages

### 7.6 Accessibility Features
- **ARIA Labels**: All interactive elements properly labeled
- **Keyboard Navigation**: Tab order follows logical flow
- **Focus Indicators**: Visible focus rings on all interactive elements
- **Screen Reader**: Announces new messages and status changes
- **High Contrast**: Supports system high contrast mode
- **Text Scaling**: Respects browser/OS text size settings
- **Color Blind Friendly**: No information conveyed by color alone

---

## 8. User Flows

### 8.1 First-Time User Flow (Onboarding)
1. User installs extension from Chrome Web Store
2. Extension icon appears in browser toolbar
3. User clicks extension icon ‚Üí popup/tab opens
4. **Empty state screen displays**:
   - Large AI assistant icon in center
   - Welcome message: "Welcome to Your Local AI Assistant"
   - Subtitle: "Privacy-First ‚Ä¢ Offline-Ready"
   - 3-4 example prompt cards visible
5. User reads examples to understand capabilities
6. User either:
   - **Option A**: Types their own question in input field
   - **Option B**: Clicks one of the example prompt cards
7. On first interaction:
   - Model download begins (if not cached)
   - Progress indicator shows: "Downloading GPT-4o (234 MB / 2.3 GB)"
   - Status updates: "Preparing model... 45%"
8. Model loads ‚Üí "‚óè AI Assistant" indicator turns green
9. AI generates welcome response
10. "Used 2 sources" indicator appears (if applicable)
11. User continues conversation or explores other features

**Success Metrics**:
- Time to first interaction: <30 seconds
- Example prompt click-through rate: >40%
- Completion of first conversation: >70%

---

### 8.2 Standard Text Generation Flow
1. User types question/prompt in input field
   - Placeholder text guides: "Ask me anything about development, coding, or technology..."
2. User presses Enter or clicks arrow button (‚Üí)
3. **Message appears in chat**:
   - User message displayed on right side with user icon (üë§)
   - Message bubble has subtle background
4. **AI response generation begins**:
   - AI message bubble appears below with assistant icon (‚ñ≤)
   - Typing indicator or cursor blink shows activity
   - Text streams token-by-token (real-time display)
5. **Response completes**:
   - Full message visible
   - Action buttons appear: [Copy] [Regenerate] [Read Aloud]
   - "Used X sources" may appear if sources were referenced
6. User can:
   - Read response and learn
   - Copy response to clipboard
   - Click "Regenerate" for different response
   - Click "Read Aloud" to hear response
   - Continue conversation with follow-up question
   - Expand "Used X sources" to see references

**Success Metrics**:
- Response latency: <2s for first token
- Streaming speed: >5 tokens/second
- User satisfaction with response quality: >80%

---

### 8.3 Voice Input Flow (Speech-to-Text)
1. User clicks microphone icon (üé§) in input bar
2. **Browser permission prompt** (first time only):
   - "AI Assistant wants to use your microphone"
   - User clicks "Allow"
3. **Recording state activates**:
   - Microphone icon changes color/pulses (visual indicator)
   - Waveform animation shows audio input (optional)
   - Timer shows recording duration
4. User speaks their question/prompt
5. User clicks microphone icon again to stop, or:
   - Auto-stops after 5 seconds of silence
6. **Processing**:
   - "Transcribing..." indicator appears briefly
   - Audio processed by local Whisper model
7. **Transcribed text appears in input field**:
   - User can review and edit if needed
   - Corrections can be made with keyboard
8. User presses Enter or clicks ‚Üí to send
9. Flow continues as standard text generation (Section 8.2)

**Success Metrics**:
- Transcription accuracy: >95% (English)
- Transcription latency: <3s for 30s audio
- Voice input usage rate: >15% of active users

---

### 8.4 Image Generation Flow
1. User types `/image` command followed by description
   - Example: `/image A futuristic city skyline at sunset`
   - Or clicks image generation example prompt
2. System detects image generation command
3. **Model check**:
   - If image model not loaded ‚Üí download begins
   - Progress: "Downloading SmolVLM-Instruct (1.8 GB)"
   - User waits or can cancel operation
4. **Generation phase**:
   - User message appears: "/image A futuristic city..."
   - AI message bubble appears with assistant icon
   - Progress indicator: "Generating image... 30%"
   - Loading spinner or progress bar visible
5. **Image rendered**:
   - Generated image displays inline in chat bubble
   - Image preview with proper sizing
   - [Download] button appears below image
6. User can:
   - Download image to device (click Download)
   - Generate another variant (Regenerate button)
   - Continue with text conversation
   - Request modifications: "Make it more colorful"

**Success Metrics**:
- Image generation success rate: >90%
- Generation time: <30s on average hardware
- Image download rate: >60% of generated images

---

### 8.5 Model Switching Flow
1. User clicks model name dropdown in input bar (e.g., "GPT-4o ÀÖ")
2. **Dropdown menu appears** showing:
   - List of available models
   - Checkmark (‚úì) next to current model
   - Model names and brief indicators
   - "‚öôÔ∏è Manage Models" option at bottom
3. User selects different model (e.g., "Phi-3.5-mini")
4. **Model loading**:
   - If model cached ‚Üí loads immediately
   - If not cached ‚Üí download begins
   - Progress shown: "Loading Phi-3.5-mini... 67%"
5. **Model activated**:
   - Dropdown closes
   - Header updates to show new model name
   - Status indicator confirms: "‚óè AI Assistant Phi-3.5-mini"
   - Toast notification: "Switched to Phi-3.5-mini"
6. User continues conversation with new model
   - Previous conversation context maintained (or optionally cleared)

**Success Metrics**:
- Model switch completion time: <10s for cached models
- Model switch usage: >30% of power users
- User satisfaction with model options: >75%

---

### 8.6 Source Attribution Flow
1. AI generates response that references external information
2. "Used X sources ÀÖ" indicator appears below AI message
3. **User clicks to expand sources**:
   - Dropdown panel opens below message
   - Shows list of source cards
4. **Each source card displays**:
   - Document icon (üìÑ)
   - Source title (e.g., "Wikipedia: Quantum Computing")
   - URL with link icon (üîó)
   - Clickable link to original source
5. User can:
   - Click source link to open in new tab
   - Verify information accuracy
   - Learn more from original sources
   - Collapse sources panel (click again)

**Success Metrics**:
- Source click-through rate: >25%
- User trust in responses with sources: >85%

---

### 8.7 Reset/Clear Chat Flow
1. User clicks "Reset" button in top-right header
2. **Confirmation dialog appears**:
   - "Clear conversation history?"
   - "This will remove all messages. This action cannot be undone."
   - [Cancel] [Clear Chat] buttons
3. User confirms by clicking "Clear Chat"
4. **Chat clears**:
   - All messages removed from view
   - Returns to empty state with example prompts
   - Toast notification: "Chat history cleared"
5. User starts fresh conversation

**Alternative**: User can press Cmd/Ctrl + L for same action

**Success Metrics**:
- Accidental clears (immediately restarted): <5%
- Intentional clear usage: 20-30% of sessions

---

### 8.8 File Attachment Flow (Future Feature)
1. User clicks attachment icon (üìé) in input bar
2. **File picker dialog opens**:
   - Supported formats: images, PDFs, text files, audio
3. User selects file(s) to upload
4. **Preview displays**:
   - Thumbnail or file name in input area
   - File size indicator
   - [√ó] button to remove attachment
5. User adds text prompt alongside file:
   - "Analyze this image and describe what you see"
   - Or sends file alone for auto-analysis
6. User presses Enter or clicks ‚Üí
7. **Processing**:
   - File uploaded/processed locally
   - AI analyzes content using multimodal model
8. AI responds with analysis in chat
9. File preview may appear in user message bubble

**Success Metrics**:
- File upload success rate: >95%
- File analysis accuracy: >80%
- Feature adoption: >20% of users

---

### 8.9 Settings Configuration Flow
1. User accesses settings via:
   - Model dropdown ‚Üí "‚öôÔ∏è Manage Models"
   - Or future settings icon in header
2. **Settings modal opens** with tabs/sections:
   - Model Configuration
   - Generation Settings
   - Storage & Cache
3. User adjusts settings:
   - **Model Config**: View current model, change default
   - **Generation**: Adjust temperature, max tokens, top-p, etc.
   - **Storage**: View cached models, clear cache
4. Settings update in real-time (with preview) or:
   - User clicks "Save Changes" to apply
5. **Confirmation**:
   - Settings saved to browser storage
   - Toast notification: "Settings saved"
   - Modal closes
6. New settings take effect on next generation

**Success Metrics**:
- Settings access rate: >40% of users
- Advanced parameter usage: >15% of users
- Setting persistence: 100% (no data loss)

---

### 8.10 Error Recovery Flow
1. **Error occurs** during operation:
   - Out of memory
   - Model download failure
   - Generation error
   - Network timeout
2. **Error message displays**:
   - User-friendly explanation
   - Icon indicating error type
   - Specific issue: "Insufficient memory to load model"
3. **Suggested actions provided**:
   - "Try a smaller model like SmolLM-135M"
   - [Switch Model] button
   - Or "Check your internet connection and retry"
   - [Retry] button
4. User follows suggestion or dismisses
5. **System attempts recovery**:
   - Falls back to smaller model (if applicable)
   - Retries operation with exponential backoff
   - Logs error for debugging (locally)
6. **Success or persistent failure**:
   - Success: Operation completes normally
   - Failure: User guided to support/documentation

**Success Metrics**:
- Error recovery success rate: >70%
- User frustration (measured by immediate exit): <10%
- Clear error messages (user feedback): >85% helpful

---